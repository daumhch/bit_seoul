ml폴더에 파일을 하나씩 확인하여 정리

# 맛보기
01: sin함수 그리기
02: iris 불러와서 LinearSVC 돌려보기, 충격적이게 빠르고 정확하다
03~04: 머신러닝의 XOR 문제, Dense를 쌓아서 해결할 수 있다 = 딥러닝 발전

# 뒤에 Classifier가 붙으면 분류 / Regressor가 붙으면 회귀
# 단 Logistic Regressor는 분류
05~08: iris, diabetes, boston, cancer에 대해
    SVC, LinearSVC, KNeighbors시리즈, RandomForest시리즈 돌려보기
09~10: wine 데이터셋, csv를 pandas로 읽어서 groupby하거나, y라벨링 그룹화

# Select Model
11: 회귀와 분류에 관련된 모든 머신러닝 돌려보기

# KFold
12: train 내부에서 val을 나눠 사용하는 상황에서, 과연 검증의 대표성이 있나?
    Cross Validtaion을 하자, 모든 데이터를 사용하여 trian/val을 하자
    cv=3하면, 1/3씩 잘라서 3번 train/val을 한다 => score 결과가 조금씩 다르다
13: KFold를 모든 머신러닝에 적용해보기 + cross_val_score 함수

# GridSearchCV, RandomizedSearchCV
14~15: iris, cancer, diabetes, boston, wine에 SearchCV 돌려보기

# Pipeline
16: 파이프라인 = 스케일링을 SearchCV에 엮어주는 기능, 스케일러를 붙일 수 있다
17: boston, wine에 파이프라인 적용

# 나무를 보지 말고 숲을 보자
18: DecisionTree들이 모인 것 = RandomForest
    RandomForest + Boosting = XGbooster
    feature importances를 확인

# PCA = 비지도학습 = 차원축소
19~22: 주성분분석

# feature importances 평가하기
23: iris, diabetes, boston, cancer, wine에 FI평가

# 과적합 방지
# 1. 훈련데이터량을 늘린다
# 2. 피쳐수를 줄인다
# 3. reguraization

# XGbooster
24: XGB 파라미터들
25: GridSearchCV, RandomizedSearchCV, cv를 위한 Pipeline
26: iris, diabetes, boston, wine에 대한 25번 수행

# SelectFromModel
27: feature_importances_의 갯수만큼 실행하여,
    Threshold와 feature갯수에 따른 score를 비교할 수 있다

# ML에서 fit 과정 표시
28~29: fit함수에서 verbose=True, eval_metric, eval_set을 지정하여 표시할 수 있다
    회귀/분류에 따라 다양한 평가 지표를 적용할 수 있다
30: ML에도 early_stopping_rounds가 있다
31: evals_result를 통해서 ML 동작 과정의 진행상태를 확인할 수 있다

# 결측치, 이상치 제거하는 여러 방법(https://pubdata.tistory.com/52)
32: outliers 사용자함수를 만들어서, 이상치를 제거해봄

33: import time

# ML 모델 저장하기
34: pickle
35: joblib
36: save_model
37: SelectFromModel을 돌려서 가장 좋은 모델을 저장하기











