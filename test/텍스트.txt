9시부터 9시까지 하기
수업이 9시 반이지만, 어쨌든 일찍 와서 미리 준비하자.

텐서플로우 2.0

자격증

2주-플젝-2주-플젝



목표:중소기업/스타트업


(레거시)머신러닝 / 딥러닝






1. 아나콘다 다운로드
https://repo.anaconda.com/archive/Anaconda3-2020.07-Windows-x86_64.exe

2. 그래픽 드라이버 최신버전 다운로드 ( RTX 2080 ) (457.09)
https://kr.download.nvidia.com/Windows/456.71/456.71-desktop-win10-64bit-international-nsd-dch-whql.exe

3. Cuba 10.1 다운로드
https://developer.nvidia.com/cuda-10.1-download-archive-update2?target_os=Windows&target_arch=x86_64&target_version=10&target_type=exelocal

4. Cudnn v7.6.5 for CUDA 10.1 다운로드
회원 가입 필수. daumhch@naver.com / 마이클1!

5. Visual Studio Code 다운로드




장비빨이 필요하다.
1060이상. GPU 필수.

발표: 나이, 이름, 개발스킬, 했던 일

선생님:윤영선

회사 = 시간을 돈으로 바꾸는 곳




https://www.tensorflow.org/


링크드인 계정 만들기


파이썬에서 리스트는 완벽하게 이해해야 한다.

조건문/반복문

함수와 클래스

이정도는 마스터 하자.



케라스 강좌
https://www.youtube.com/channel/UCvjXlZjlyAp2uZusgDn8lxA/videos

인공지능 블로그
https://blog.naver.com/gema0000



1. 아나콘다 설치하기

아나콘다 설치하면 파이썬+API들이 자동 설치된다.
왠만하면 아나콘다를 설치하자.
설치 폴더는 C:\Anaconda3
Path까지 추가하는거 체크하고 설치하자.


파이썬 3.8.3 사용


2/3/4 -> GPU를 사용하기 위해서.

2. 그래픽카드 설치 -> 사용자 정의 -> 그래픽 드라이버만 설치

3. CUDA 설치 -> 첫번째거 '+'눌러서 Visual Studio Integration 체크 해제

4. cudnn 압축 풀고 
-> C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.1 에 덮어쓰기


###숙제 : 설치하고 스크린샷 찍어서 보내기
nvida를 쓰지 않으면 2,3,4를 빼고.


conda env list
설치된 리스트 확인


텐서플로우 설치하기
pip install tensorflow-gpu==2.3.0

cpu gpu 두 버전이 있지만, 2.3.0에서는 tensorflow로만 설치하면 둘 다 설치.


python에서,
import tensorflow as tf 하면 에러가 날 것이다.

https://support.microsoft.com/en-us/help/2977003/the-latest-supported-visual-c-downloads
에서 x64 버전을 설치하면, 정상 실행이 될 것이다.
(Successfully opened dynamic library cudart64_101.dll)


텐서플로우 1.0이 어려워서 나온 게 케라스(keras) API

1.0 -> 2.0 
텐서플로우 안에 keras 포함.
내부 포함이니 속도가 더 빨라짐.


케라스 설치하기
pip install keras==2.4.3

텐서플로우 확인하기
import tensorflow as tf
import keras

###숙제: numpy ..?


###숙제: 케글 가입하고 반장에게 전달.
가입하기
1. kaggle  https://www.kaggle.com/BaeHyunChul
2. DACON
3. github -> bit_seoul 저장소 만들어서 Study와 같게


==이론수업
인공지능 >= 머신러닝 > 딥러닝


뇌의 신경망

머신러닝+인공신경망 = 딥러닝

노드 = 신경망 안에 하나의 지점
레이어 = 신경망 세로 한 줄의 단계

신경망 구성하는 거 = 모델링

y=ax+b

lost / cost

훈련구간 = '정제된 데이터' x와 y를 넣는다

y=ax+b -> y=wx+b (w=weight)

머신은 '최적의' w를 구한다. (b는 영향이 작다)

또한 머신은 '최소의' loss가 되는 계산을 한다.


숙제 : acc가 왜 0.2일까, 1로 맞춰보자.


딥러닝에서,
노드의 개수와 레이어 깊이,
epochs, batch_size 등은
개발자가 정한다.

하이퍼 파라미터 튜닝 = 노드와 레이어, epochs, batch_size 조정





201110
입력레이어
히든레이어
출력레이어

하이퍼 파라미터 튜닝은, 히든레이어 조정하는 것

훈련데이터와 평가데이터는 나뉘어야 한다

정제된 데이터 = 전처리 하지 않은 데이터

최적의 weight

최소의 loss

MSE = mean_squared_error

MAE = mean_absolute_error

실제값과 예측값의 차이를 평가할 때,
음수값을 대응하기 위해 MSE 또는 MAE를 사용한다

batch_size가 크면 일괄처리 하니까 속도가 빠르다
너무 크면 제대로 된 훈련이 안 된다
(=그래픽카드 메모리가 넘친다)
batch_size도 최적화가 필요하다


loss 평가 방법
0.1 vs 0.01
낮으면 낮을수록 좋은데,
객관적인 수치는 없다


accuracy가 0.5이하는 의미 없다
할 필요가 없다


1과 0.999~~를 다르게 생각해야 한다
그래서 선형회귀에서는 accuracy를 쓸 수 없다

딥러닝 평가방식
1. 회귀 = 결과 값이 숫자로 나올 때
2. 분류 = 결과 종류가 정해져 있을 때


ctrl+/ 라인 주석
ctrl+c 라인 복사
shift+del 라인 삭제


평가 지표 중 loss는 default,
나머지는 metrics에서 추가하면 나온다

model.evaluate의 return은 list이다

metrics=['mse']를 하면
loss와 같은 값이 나온다


실습:결과물 오차 수정 및 미세조정
정답은 없지만 최적은 있다


소스 수정없이 실행했는데,
매번 결과가 다른 건 당연하다

실행할 때마다 accuracy가 
1. 1->0.5->1->0.5인 경우
2. 0.7->0.7->0.7->0.7인 경우
2번이 더 안정적인 성능을 보인 것


RMSE 지표


사이킷런


R2 결정계수
회귀분야에서 accuracy 대신 쓰는 지표


loss, RMSE, R2 항상 같이 다닌다


레이어구조는,
사각박스이거나,
다이아몬드 모양이거나,
역삼각형 모양이, 그나마 낫다

튜닝은 계속 해봐야 한다


validation(검증)
머신에게 훈련시킬 데이터의 일부를,
검증용으로 빼는 것

fit에다가 '변수_val'을 추가
또는 validation_split을 지정(퍼센트를 소수점으로)


파이썬에서 array 자르는 것 잘 기억해두자
x_train = x[:60] # 60개 
여기서 60은 값이 아니라 인덱스다

y = np.array(range(101, 201))인 경우
y_train = y[:60] 이렇게 해야 60개를 자른다


훈련데이터:검증데이터:평가용데이터 = 6:2:2


train_test_split으로 나누면,
데이터가 섞여서 분리된다 (순차적이지 않다)
단 설정된 비율은 지키면서 분리된다


순차적으로 분리하고 싶으면,
shuffle=False 옵션을 추가한다








입력이 N개가 될 수 있고,
출력도 N개가 될 수 있다

날씨/온도/습도 가지고 날씨/온도/습도 를 예측할 수 있다


column = 열
row = 행


array 객체 하나하나 = 스칼라

(30,) = 스칼라 30개, 1차원

벡터 = 스칼라의 배열, 1차원

행렬 = 2차원

텐서 = 다차원





(30,) = 30개의 스칼라가 모여있는 것
(30,1) = 30행 1열

[[1,2,3],[4,5,6]] = 2행 3열 = (2,3)

[[1,2,3,4,5,6]] = 1행 6열 = (1,6)

[[1,2],[3,4],[5,6]] = 3행 2열 = (3,2)

[[[1,2,3],[4,5,6]]] = 1x2x3 = 면x행x열
[1,2,3,4,5,6] = 6열 = (6,)

행렬 공부하자



위키독스
딥 러닝을 이용한 자연어 처리 입문 08. 딥 러닝(Deep Learnin ... 6) 케라스(Keras) 훑어보기

https://wikidocs.net/32105





201111

X-Y의 상관관계는 중요한가?
주식/채권/환율 - 기온 관계를 모델링을,
'할 수 있다'

데이터만 준비되어 있다면,
무엇이든 모델링을 할 수는 있다
평가지표가 나쁠 수는 있어도

1차원
y = w*x+b

다차원
y1, y2, y3... = w1*x1 + w2*x2 + ... + b



### 행무시 열우선
= 중요한 건 '열(column)'
= 행은 단지 나열되었을 뿐



보편적이고 일반적인건
x가 여러개 y는 하나



별도의 이야기가 없어도,
R2 높이고,
RMSE 낮추고,
loss 낮춰야 한다 = 튜닝은 꾸준히




### mlp할 때 수동으로 슬라이싱 연습하자
수동으로 자를 때에도,
다차원 배열이라 하더라도
슬라이스가 자동으로 된다



# 앞으로는 input_shape를 사용한다



validation을 넣으면서,
epoch 출력 결과에
loss와 val_loss 차이가 있다

val_loss를 통해 최적 epoch를 구할 수 있다



==== Sequential 기초 끝 ====




함수형 모델

함수를 사용하는 목적: 재사용



activation = 활성화 함수
레이어 전달 할 때,
문제 있는 값을 정리하는 기능
모든 레이어 마다 있다
Dense layer의 default activatin은 'linear'
'relu'를 사용하는 게 무난하다
마지막 activation은 'linear' 해야 한다




시퀀셜 모델은,
모델 정의하고 구성했다면,

함수형 모델은,
구성을 먼저하고 모델을 정의한다


model.summary()에서
모델을 확인했을 때,
param의 결과가
배치된 layer 및 node 개수와 다른 이유는,

node 개수에 바이어스노드(+1) 해주기 때문



### 내 생각
https://stackoverflow.com/questions/2480650/what-is-the-role-of-the-bias-in-neural-networks

y=w*x+b = w*x+b*1

모델 안에는 연산이기 때문에,
b 또한 b*1로 생각하여 연산한다
그래야 찾을 수 있을 것 같다

### 내 생각 끝


함수형 모델의 summary는
Model: "functional_1"
이런 형태로 메시지가 나온다




### 앙상블(ensemble)

모델의 신뢰성 이전에,

데이터 신뢰성은 어떻게?

=도박사의 오류=
서로 영향을 끼치지 않는 일련의 확률적 사건들에서 
상관관계를 찾아내려 하는 사고의 오류를 이야기한다.



데이터를 합치지 않고,
데이터별로 모델을 만들어서,
모델을 합친다 = concatenate


input model 2

middle 1

output model 2

총 5개




https://keras.co.kr/
선생님 홈페이지

https://keras.io/
참고 페이지

이름붙이고 싶으면 Dense 파라미터 name을 사용하자


Concatenate와 concatenate는 다르다
Concatenate를 사용할 때에는 axis를 설정해야 한다
ex) keras16_ensemble.py
0 = 가장 높은 차원 기준으로 합치기 -> Total params = 2323
1 = 두번째로 높은 차원 기준으로 합치기 -> Total params = 2413
-1 = 가장 낮은 차원 기준으로 합치기 -> Total params = 2413




숙제: 앙상블 예제 3번 튜닝하기


내일은 LSTM


201112

복습
시퀀셜 -> 함수형 모델
모델 섞기 -> 앙상블
튜너


오늘은 LSTM 할 예정

DNN = deep neural networks
RNN = recurrent neural networks 
- LSTM = Long Short-Term Memory models

RNN = 순환 신경망 = 순차적인 데이터 분석 = Time Series = 시계열
시계열이라 하여 주식/온도 처럼 시간데이터 뿐 아니라,
'나는 밥을 먹는다'처럼, 텍스트 또한 순차적인 의미가 있다
자연어 처리, 챗봇의 기초


1, 2, 3, 4 라는 데이터에서,
다음 값이 5라고 예상되는 이유는, weight와 bias를 경험적으로 계산했기 때문에


LSTM = 가장 좋은 성능의 RNN
https://gruuuuu.github.io/machine-learning/lstm-doc2/#

GRU = LSTM을 더 발전시킨 구조


LSTM 파라미터 계산 방법
https://en.wikipedia.org/wiki/Long_short-term_memory#/media/File:LSTM_cell.svg

4*(n+m+b)*m
4 = sigmoid 3개 + tanh 1개
n = input vector
m = LSTM layer number
b = bias = 1


내 생각에,
feedback이 아니고 recurrent인 이유: 값 + 상태를 되먹인다


input_shape = (input_length , input_dim)



simpleRNN은,
(n+m+b)*m = parameter의 수

GRU는,
### 조사하자



하이퍼파리미터 튜닝 조건 추가 : EarlyStopping에서 patience 지표




keras22_Return_sequences.py
ValueError: Input 0 of layer lstm_1 is incompatible with the layer: 
expected ndim=3, found ndim=2. Full shape received: [None, 64] 

-> 3차원 기대했는데 2차원을 확인했다


return_sequences가 default False인데,
LSTM에서 입력은 3차원, 결과는 2차원인데,
return_sequences를 True로 하면 3차원 반환


LSTM을 2개 엮으려면 return_sequences=True로 설정하면 되지만,
모델 효율이 좋을까? (좋지 않아 보인다)




201112 끝

내일은 데이터 전처리 하는 날

RNN CNN은 꼭 알자




How to Diagnose Overfitting and Underfitting of LSTM Models

https://machinelearningmastery.com/diagnose-overfitting-underfitting-lstm-models/



텐서플로우 API 설명
https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit





201113

전날 정리
Dense에는 shape 입력이 2차원 -> input_shape = (1,) 처럼 -> 행무시 열우선
LSTM(RNN계열) -> shape 입력이 3차원(행,열,몇개씩자르는지) -> (?,단위)
CNN(오늘 할거) -> shape 입력이 4차원 -> (?,?,?)
=====이정도 하면 2019년 기준 취업 가능


2차원으로 받은 시계열 데이터를 3차원으로 reshape 했다

LSTM, SRNN, GRU 했을 때,
아직까진 LSTM이 성능이 낫다(느린건 장비빨로 커버 가능하니까)


알고리즘 원리를 이해하는 것도 중요하긴 한데,
사용법이 더 중요하니 일단 수업에 집중하자



모델 훈련을 위해서는,
x와 y가 있어야 하는데,
시계열 데이터는 일반적으로 y가 없다


# [ 1  2  3  4  5  6  7  8  9 10] 를
split_x(10, 5) 함수를 통해

# [ 1  2  3  4  5]
# [ 2  3  4  5  6]
# [ 3  4  5  6  7]
# [ 4  5  6  7  8]
# [ 5  6  7  8  9]
# [ 6  7  8  9 10]

이렇게 바꾸면,
LSTM을 통해
(5,4)를 (5,4,1)로 reshape 하고 모델을 돌릴 수 있다


케라스 모델 저장 확장자는 h5

VSC에서는 파일을 저장하는 곳은, 작업그룹(root)에 저장된다
파이참에서는, 현재 폴더가 root가 된다


모델을 h5나 json으로 저장/로드 하는 법
https://3months.tistory.com/150


모델 불러올 때의 주의점은,
레이어의 이름은 겹치면 안 된다





주말에 dictionary 공부하기


앞으로는,
취미 = 하이퍼 파라미터
특기 = 데이터 전처리


데이터 전처리 하는 이유는
연산하면서 값이 엄청 클 수도 있다, 그걸 막는게 좋지 않을까

데이터를 최대값으로 나눠서 0~1 사이로 압축한다면? 괜찮겠다 
-> 데이터 스케일 바꾸면 조작 아냐?
-> x와 y의 1:1대응은 변하지 않으니 괜찮다
-> 데이터 전처리에서 y는 건들지 않는다



전처리 방식

x = (x-최소)/(최대-최소)

from sklearn.preprocessing import MinMaxScaler
이런 좋은 도구가 이미 있다


train만 fit+transform
val/test/predict는 transform만 한다


### 과제+실습
- StandardScaler
- RobustScaler
- MaxAbsScaler
위의 세 개를 정리하라


### 월요일부터 CNN 한다

데이터 표준화 정규화 관련 읽어볼 사이트

- 데이터 일반화 vs 표준화
https://skyil.tistory.com/50

"Normalization은 값을 0과 1 사이로 모아서 값의 규모(scale)를 줄여준다. 
min과 max의 편차가 크거나, 다른 열에 비해 데이터가 지나치게 큰 열에 사용한다."

"Standardization은 z-score의 절댓값이 2를 넘는 값들을 지워 
평균에서 크게 벗어난 outlier를 제거한다. 
이는 모델이 대부분의 상황에서 더 높은 precision을 갖게 한다."


## 보통 데이터 전처리 순서를,
표준화
이상치 제거 (z-score 활용)
정규화
순서로 한다




### 체감 상,
입력 데이터를 스케일러(표준화 및 정규화)를 하면,
epoch가 커진다 (더 많이 돌리는 경향이 있는 것 같다)



201116 수업시작

저번 주 복습


모델 차원
LSTM 3차원 = 행 / 열 / 몇 개씩 자르는지
DNN 2차원 = 행 / 열
CNN 4차원 = 이미지 갯수 / 가로 / 세로 / RGB


return_sequences = 입력차원 그대로 다음 레이어로 넘기기
LSTM 여러개 연결할 때 사용



모델부터 공부한 이유, 쉬워서


AI디벨로퍼 vs 데이터 사이언티스트


85% 데이터 전처리
15% 모델링


전이학습 = 잘 만든 weight와 model을 가져다 쓰자


스케일링
(내생각) 제일 무난한게 MinMaxScaler, StandardScaler
               X        |    Y
train | fit / transform |    x 
test  |    transform    |    x
val   |    transform    |    x
pred  |    transform    | 값 없음




CNN
컴퓨터는 그림을 숫자로 인식한다 (가로,세로,픽셀)
머신이 그림을 인식할 수 있게, 그림을 잘라서 입력할 수 있다

1x1씩 자르는 게 아니라, 2x2씩 자른다면,
특성값(feature)을 중첩시켜서 머신이 더 확실하게 구분짓도록 유도할 수 있다

이렇게 조각내서 연산하는 방식이 CNN = Convolution Neural Network




특성 중첩을 통해 특징이 더 드러나기 때문에
Convolution layer는 엮을수록 성능이 좋아진다


보통의 프로세스
conv2d를 통과시켜 증폭시키다가
dense를 통과시키면서 압축시킨다



conv2d의 filters 숫자 또한 RNN에서 node개수 처럼,
데이터마다 최적지점이 다르다
사용자가 계산해야 한다


Convolution 에서는, 출력에서 차원이 줄어들지 않는다
LSTM에서 return_sequences 같은 걸 하지 않아도 된다



이미지를 자르는데, 중복시키지 않고 자르는 경우 
= 잘라낸 범위별로 최대값만 찾는 경우
= MaxPooling2D
= (내생각)커진 데이터 이미지를 다시 압축할 때 사용하는 것 같다
https://keras.io/ko/layers/pooling/



Conv2d layer parameter = nowLayer * (width * height * prevLayer +1)




### mnist = 0~9까지의 손글씨 데이터베이스

# 분류 할 때에 중요한 점
각각의 결과값은 동일한 가치를 가져야 한다

# 회귀에서는 RMSE R2 수치를 높이는 게 목표라면
# 분류에서는 분류 결과들이 평등하다는 것을 알려줘야 한다 = One-Hot Encoding
https://wikidocs.net/22647
https://needjarvis.tistory.com/565


### one hot encoding
결과값에 인덱스를 붙여,
분류 할 때에 동일한 가중치를 부여하는 방식

from tensorflow.keras.utils import to_categorical

from sklearn.preprocessing import OneHotEncoder




LSTM의 default activation 
= Default: hyperbolic tangent (tanh)
https://keras.io/api/layers/recurrent_layers/lstm/

Conv2D의 default activation 
= relu
https://keras.io/api/layers/convolution_layers/convolution2d/


다중분류 할 때, 
y 라벨링을 one hot encoding = to_categorical,
마지막 Dense의 activation은 softmax,
컴파일 loss는 categorical_crossentropy


softmax에 의해 나온 결과들을 모두 합치면 1이 된다 ()



201117

mnist에 대한 구현은,

CNN, DNN, LSTM(RNN) 다 가능하다, 가능해야한다



코랩
https://colab.research.google.com/

소스 넣고 돌리면 알아서 동작한다


## 내가 한 중간 질문
model.add(Dense(50))
model.add(activation=~~~) 이런 형태로 따로 돌리기도 하는데,
이건, model.add(Dense(50, activation=~~~))와 같다




### cifar10 데이터셋
그림데이터, (60000,32,32,3)
https://www.cs.toronto.edu/~kriz/cifar.html

airplane : 0
automobile : 1
bird : 2
cat : 3
deer : 4
dog : 5
frog : 6
horse : 7
ship : 8
truck : 9


validation accuracy와 train accuracy가 너무 멀면 과적합



### fashion_mnist 데이터셋
0 T-shirt/top
1 Trouser
2 Pullover
3 Dress
4 Coat
5 Sandal
6 Shirt
7 Sneaker
8 Bag
9 Ankle boot


# cifar100 데이터셋


# cnn 개선하는데 참고중인 사이트들
https://towardsdatascience.com/cifar-10-image-classification-in-tensorflow-5b501f7dc77c

https://buomsoo-kim.github.io/keras/2018/05/05/Easy-deep-learning-with-Keras-11.md/

https://github.com/buomsoo-kim/Easy-deep-learning-with-Keras/blob/master/2.%20CNN/2-Advanced-CNN/2-advanced-cnn.ipynb

https://www.machinecurve.com/index.php/2020/02/09/how-to-build-a-convnet-for-cifar-10-and-cifar-100-classification-with-keras/

https://boysboy3.tistory.com/105

https://stackoverflow.com/questions/58567253/how-would-i-increase-my-accuracy-in-the-cifar-100-dataset-i-have-a-10-accuracy





