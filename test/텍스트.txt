9시부터 9시까지 하기
수업이 9시 반이지만, 어쨌든 일찍 와서 미리 준비하자.

텐서플로우 2.0

자격증

2주-플젝-2주-플젝



목표:중소기업/스타트업


(레거시)머신러닝 / 딥러닝






1. 아나콘다 다운로드
https://repo.anaconda.com/archive/Anaconda3-2020.07-Windows-x86_64.exe

2. 그래픽 드라이버 최신버전 다운로드 ( RTX 2080 ) (457.09)
https://kr.download.nvidia.com/Windows/456.71/456.71-desktop-win10-64bit-international-nsd-dch-whql.exe

3. Cuba 10.1 다운로드
https://developer.nvidia.com/cuda-10.1-download-archive-update2?target_os=Windows&target_arch=x86_64&target_version=10&target_type=exelocal

4. Cudnn v7.6.5 for CUDA 10.1 다운로드
회원 가입 필수. daumhch@naver.com / 마이클1!

5. Visual Studio Code 다운로드




장비빨이 필요하다.
1060이상. GPU 필수.

발표: 나이, 이름, 개발스킬, 했던 일

선생님:윤영선

회사 = 시간을 돈으로 바꾸는 곳




https://www.tensorflow.org/


링크드인 계정 만들기


파이썬에서 리스트는 완벽하게 이해해야 한다.

조건문/반복문

함수와 클래스

이정도는 마스터 하자.



케라스 강좌
https://www.youtube.com/channel/UCvjXlZjlyAp2uZusgDn8lxA/videos

인공지능 블로그
https://blog.naver.com/gema0000



1. 아나콘다 설치하기

아나콘다 설치하면 파이썬+API들이 자동 설치된다.
왠만하면 아나콘다를 설치하자.
설치 폴더는 C:\Anaconda3
Path까지 추가하는거 체크하고 설치하자.


파이썬 3.8.3 사용


2/3/4 -> GPU를 사용하기 위해서.

2. 그래픽카드 설치 -> 사용자 정의 -> 그래픽 드라이버만 설치

3. CUDA 설치 -> 첫번째거 '+'눌러서 Visual Studio Integration 체크 해제

4. cudnn 압축 풀고 
-> C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.1 에 덮어쓰기


###숙제 : 설치하고 스크린샷 찍어서 보내기
nvida를 쓰지 않으면 2,3,4를 빼고.


conda env list
설치된 리스트 확인


텐서플로우 설치하기
pip install tensorflow-gpu==2.3.0

cpu gpu 두 버전이 있지만, 2.3.0에서는 tensorflow로만 설치하면 둘 다 설치.


python에서,
import tensorflow as tf 하면 에러가 날 것이다.

https://support.microsoft.com/en-us/help/2977003/the-latest-supported-visual-c-downloads
에서 x64 버전을 설치하면, 정상 실행이 될 것이다.
(Successfully opened dynamic library cudart64_101.dll)


텐서플로우 1.0이 어려워서 나온 게 케라스(keras) API

1.0 -> 2.0 
텐서플로우 안에 keras 포함.
내부 포함이니 속도가 더 빨라짐.


케라스 설치하기
pip install keras==2.4.3

텐서플로우 확인하기
import tensorflow as tf
import keras

###숙제: numpy ..?


###숙제: 케글 가입하고 반장에게 전달.
가입하기
1. kaggle  https://www.kaggle.com/BaeHyunChul
2. DACON
3. github -> bit_seoul 저장소 만들어서 Study와 같게


==이론수업
인공지능 >= 머신러닝 > 딥러닝


뇌의 신경망

머신러닝+인공신경망 = 딥러닝

노드 = 신경망 안에 하나의 지점
레이어 = 신경망 세로 한 줄의 단계

신경망 구성하는 거 = 모델링

y=ax+b

lost / cost

훈련구간 = '정제된 데이터' x와 y를 넣는다

y=ax+b -> y=wx+b (w=weight)

머신은 '최적의' w를 구한다. (b는 영향이 작다)

또한 머신은 '최소의' loss가 되는 계산을 한다.


숙제 : acc가 왜 0.2일까, 1로 맞춰보자.


딥러닝에서,
노드의 개수와 레이어 깊이,
epochs, batch_size 등은
개발자가 정한다.

하이퍼 파라미터 튜닝 = 노드와 레이어, epochs, batch_size 조정





201110
입력레이어
히든레이어
출력레이어

하이퍼 파라미터 튜닝은, 히든레이어 조정하는 것

훈련데이터와 평가데이터는 나뉘어야 한다

정제된 데이터 = 전처리 하지 않은 데이터

최적의 weight

최소의 loss

MSE = mean_squared_error

MAE = mean_absolute_error

실제값과 예측값의 차이를 평가할 때,
음수값을 대응하기 위해 MSE 또는 MAE를 사용한다

batch_size가 크면 일괄처리 하니까 속도가 빠르다
너무 크면 제대로 된 훈련이 안 된다
(=그래픽카드 메모리가 넘친다)
batch_size도 최적화가 필요하다


loss 평가 방법
0.1 vs 0.01
낮으면 낮을수록 좋은데,
객관적인 수치는 없다


accuracy가 0.5이하는 의미 없다
할 필요가 없다


1과 0.999~~를 다르게 생각해야 한다
그래서 선형회귀에서는 accuracy를 쓸 수 없다

딥러닝 평가방식
1. 회귀 = 결과 값이 숫자로 나올 때
2. 분류 = 결과 종류가 정해져 있을 때


ctrl+/ 라인 주석
ctrl+c 라인 복사
shift+del 라인 삭제


평가 지표 중 loss는 default,
나머지는 metrics에서 추가하면 나온다

model.evaluate의 return은 list이다

metrics=['mse']를 하면
loss와 같은 값이 나온다


실습:결과물 오차 수정 및 미세조정
정답은 없지만 최적은 있다


소스 수정없이 실행했는데,
매번 결과가 다른 건 당연하다

실행할 때마다 accuracy가 
1. 1->0.5->1->0.5인 경우
2. 0.7->0.7->0.7->0.7인 경우
2번이 더 안정적인 성능을 보인 것


RMSE 지표


사이킷런


R2 결정계수
회귀분야에서 accuracy 대신 쓰는 지표


loss, RMSE, R2 항상 같이 다닌다


레이어구조는,
사각박스이거나,
다이아몬드 모양이거나,
역삼각형 모양이, 그나마 낫다

튜닝은 계속 해봐야 한다


validation(검증)
머신에게 훈련시킬 데이터의 일부를,
검증용으로 빼는 것

fit에다가 '변수_val'을 추가
또는 validation_split을 지정(퍼센트를 소수점으로)


파이썬에서 array 자르는 것 잘 기억해두자
x_train = x[:60] # 60개 
여기서 60은 값이 아니라 인덱스다

y = np.array(range(101, 201))인 경우
y_train = y[:60] 이렇게 해야 60개를 자른다


훈련데이터:검증데이터:평가용데이터 = 6:2:2


train_test_split으로 나누면,
데이터가 섞여서 분리된다 (순차적이지 않다)
단 설정된 비율은 지키면서 분리된다


순차적으로 분리하고 싶으면,
shuffle=False 옵션을 추가한다








입력이 N개가 될 수 있고,
출력도 N개가 될 수 있다

날씨/온도/습도 가지고 날씨/온도/습도 를 예측할 수 있다


column = 열
row = 행


array 객체 하나하나 = 스칼라

(30,) = 스칼라 30개, 1차원

벡터 = 스칼라의 배열, 1차원

행렬 = 2차원

텐서 = 다차원





(30,) = 30개의 스칼라가 모여있는 것
(30,1) = 30행 1열

[[1,2,3],[4,5,6]] = 2행 3열 = (2,3)

[[1,2,3,4,5,6]] = 1행 6열 = (1,6)

[[1,2],[3,4],[5,6]] = 3행 2열 = (3,2)

[[[1,2,3],[4,5,6]]] = 1x2x3 = 면x행x열
[1,2,3,4,5,6] = 6열 = (6,)

행렬 공부하자



위키독스
딥 러닝을 이용한 자연어 처리 입문 08. 딥 러닝(Deep Learnin ... 6) 케라스(Keras) 훑어보기

https://wikidocs.net/32105





201111

X-Y의 상관관계는 중요한가?
주식/채권/환율 - 기온 관계를 모델링을,
'할 수 있다'

데이터만 준비되어 있다면,
무엇이든 모델링을 할 수는 있다
평가지표가 나쁠 수는 있어도

1차원
y = w*x+b

다차원
y1, y2, y3... = w1*x1 + w2*x2 + ... + b



### 행무시 열우선
= 중요한 건 '열(column)'
= 행은 단지 나열되었을 뿐



보편적이고 일반적인건
x가 여러개 y는 하나



별도의 이야기가 없어도,
R2 높이고,
RMSE 낮추고,
loss 낮춰야 한다 = 튜닝은 꾸준히




### mlp할 때 수동으로 슬라이싱 연습하자
수동으로 자를 때에도,
다차원 배열이라 하더라도
슬라이스가 자동으로 된다



# 앞으로는 input_shape를 사용한다



validation을 넣으면서,
epoch 출력 결과에
loss와 val_loss 차이가 있다

val_loss를 통해 최적 epoch를 구할 수 있다



==== Sequential 기초 끝 ====




함수형 모델

함수를 사용하는 목적: 재사용



activation = 활성화 함수
레이어 전달 할 때,
문제 있는 값을 정리하는 기능
모든 레이어 마다 있다
Dense layer의 default activatin은 'linear'
'relu'를 사용하는 게 무난하다
마지막 activation은 'linear' 해야 한다




시퀀셜 모델은,
모델 정의하고 구성했다면,

함수형 모델은,
구성을 먼저하고 모델을 정의한다


model.summary()에서
모델을 확인했을 때,
param의 결과가
배치된 layer 및 node 개수와 다른 이유는,

node 개수에 바이어스노드(+1) 해주기 때문



### 내 생각
https://stackoverflow.com/questions/2480650/what-is-the-role-of-the-bias-in-neural-networks

y=w*x+b = w*x+b*1

모델 안에는 연산이기 때문에,
b 또한 b*1로 생각하여 연산한다
그래야 찾을 수 있을 것 같다

### 내 생각 끝


함수형 모델의 summary는
Model: "functional_1"
이런 형태로 메시지가 나온다




### 앙상블(ensemble)

모델의 신뢰성 이전에,

데이터 신뢰성은 어떻게?

=도박사의 오류=
서로 영향을 끼치지 않는 일련의 확률적 사건들에서 
상관관계를 찾아내려 하는 사고의 오류를 이야기한다.



데이터를 합치지 않고,
데이터별로 모델을 만들어서,
모델을 합친다 = concatenate


input model 2

middle 1

output model 2

총 5개




https://keras.co.kr/
선생님 홈페이지

https://keras.io/
참고 페이지

이름붙이고 싶으면 Dense 파라미터 name을 사용하자


Concatenate와 concatenate는 다르다
Concatenate를 사용할 때에는 axis를 설정해야 한다
ex) keras16_ensemble.py
0 = 가장 높은 차원 기준으로 합치기 -> Total params = 2323
1 = 두번째로 높은 차원 기준으로 합치기 -> Total params = 2413
-1 = 가장 낮은 차원 기준으로 합치기 -> Total params = 2413




숙제: 앙상블 예제 3번 튜닝하기


내일은 LSTM


201112

복습
시퀀셜 -> 함수형 모델
모델 섞기 -> 앙상블
튜너


오늘은 LSTM 할 예정

DNN = deep neural networks
RNN = recurrent neural networks 
- LSTM = Long Short-Term Memory models

RNN = 순환 신경망 = 순차적인 데이터 분석 = Time Series = 시계열
시계열이라 하여 주식/온도 처럼 시간데이터 뿐 아니라,
'나는 밥을 먹는다'처럼, 텍스트 또한 순차적인 의미가 있다
자연어 처리, 챗봇의 기초


1, 2, 3, 4 라는 데이터에서,
다음 값이 5라고 예상되는 이유는, weight와 bias를 경험적으로 계산했기 때문에


LSTM = 가장 좋은 성능의 RNN
https://gruuuuu.github.io/machine-learning/lstm-doc2/#

GRU = LSTM을 더 발전시킨 구조


LSTM 파라미터 계산 방법
https://en.wikipedia.org/wiki/Long_short-term_memory#/media/File:LSTM_cell.svg

4*(n+m+b)*m
4 = sigmoid 3개 + tanh 1개
n = input vector
m = LSTM layer number
b = bias = 1


내 생각에,
feedback이 아니고 recurrent인 이유: 값 + 상태를 되먹인다


input_shape = (input_length , input_dim)



simpleRNN은,
(n+m+b)*m = parameter의 수

GRU는,
### 조사하자



하이퍼파리미터 튜닝 조건 추가 : EarlyStopping에서 patience 지표




keras22_Return_sequences.py
ValueError: Input 0 of layer lstm_1 is incompatible with the layer: 
expected ndim=3, found ndim=2. Full shape received: [None, 64] 

-> 3차원 기대했는데 2차원을 확인했다


return_sequences가 default False인데,
LSTM에서 입력은 3차원, 결과는 2차원인데,
return_sequences를 True로 하면 3차원 반환


LSTM을 2개 엮으려면 return_sequences=True로 설정하면 되지만,
모델 효율이 좋을까? (좋지 않아 보인다)




201112 끝

내일은 데이터 전처리 하는 날

RNN CNN은 꼭 알자




How to Diagnose Overfitting and Underfitting of LSTM Models

https://machinelearningmastery.com/diagnose-overfitting-underfitting-lstm-models/



텐서플로우 API 설명
https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit





201113

전날 정리
Dense에는 shape 입력이 2차원 -> input_shape = (1,) 처럼 -> 행무시 열우선
LSTM(RNN계열) -> shape 입력이 3차원(행,열,몇개씩자르는지) -> (?,단위)
CNN(오늘 할거) -> shape 입력이 4차원 -> (?,?,?)
=====이정도 하면 2019년 기준 취업 가능


2차원으로 받은 시계열 데이터를 3차원으로 reshape 했다

LSTM, SRNN, GRU 했을 때,
아직까진 LSTM이 성능이 낫다(느린건 장비빨로 커버 가능하니까)


알고리즘 원리를 이해하는 것도 중요하긴 한데,
사용법이 더 중요하니 일단 수업에 집중하자



모델 훈련을 위해서는,
x와 y가 있어야 하는데,
시계열 데이터는 일반적으로 y가 없다


# [ 1  2  3  4  5  6  7  8  9 10] 를
split_x(10, 5) 함수를 통해

# [ 1  2  3  4  5]
# [ 2  3  4  5  6]
# [ 3  4  5  6  7]
# [ 4  5  6  7  8]
# [ 5  6  7  8  9]
# [ 6  7  8  9 10]

이렇게 바꾸면,
LSTM을 통해
(5,4)를 (5,4,1)로 reshape 하고 모델을 돌릴 수 있다


케라스 모델 저장 확장자는 h5

VSC에서는 파일을 저장하는 곳은, 작업그룹(root)에 저장된다
파이참에서는, 현재 폴더가 root가 된다


모델을 h5나 json으로 저장/로드 하는 법
https://3months.tistory.com/150


모델 불러올 때의 주의점은,
레이어의 이름은 겹치면 안 된다





주말에 dictionary 공부하기


앞으로는,
취미 = 하이퍼 파라미터
특기 = 데이터 전처리


데이터 전처리 하는 이유는
연산하면서 값이 엄청 클 수도 있다, 그걸 막는게 좋지 않을까

데이터를 최대값으로 나눠서 0~1 사이로 압축한다면? 괜찮겠다 
-> 데이터 스케일 바꾸면 조작 아냐?
-> x와 y의 1:1대응은 변하지 않으니 괜찮다
-> 데이터 전처리에서 y는 건들지 않는다



전처리 방식

x = (x-최소)/(최대-최소)

from sklearn.preprocessing import MinMaxScaler
이런 좋은 도구가 이미 있다


데이터 스케일링 그림 비교자료
https://homeproject.tistory.com/3



train만 fit+transform
val/test/predict는 transform만 한다


### 과제+실습
- StandardScaler
- RobustScaler
- MaxAbsScaler
위의 세 개를 정리하라


### 월요일부터 CNN 한다

데이터 표준화 정규화 관련 읽어볼 사이트

- 데이터 일반화 vs 표준화
https://skyil.tistory.com/50

"Normalization은 값을 0과 1 사이로 모아서 값의 규모(scale)를 줄여준다. 
min과 max의 편차가 크거나, 다른 열에 비해 데이터가 지나치게 큰 열에 사용한다."

"Standardization은 z-score의 절댓값이 2를 넘는 값들을 지워 
평균에서 크게 벗어난 outlier를 제거한다. 
이는 모델이 대부분의 상황에서 더 높은 precision을 갖게 한다."


## 보통 데이터 전처리 순서를,
표준화
이상치 제거 (z-score 활용)
정규화
순서로 한다




### 체감 상,
입력 데이터를 스케일러(표준화 및 정규화)를 하면,
epoch가 커진다 (더 많이 돌리는 경향이 있는 것 같다)



201116 수업시작

저번 주 복습


모델 차원
LSTM 3차원 = 행 / 열 / 몇 개씩 자르는지
DNN 2차원 = 행 / 열
CNN 4차원 = 이미지 갯수 / 가로 / 세로 / RGB


return_sequences = 입력차원 그대로 다음 레이어로 넘기기
LSTM 여러개 연결할 때 사용



모델부터 공부한 이유, 쉬워서


AI디벨로퍼 vs 데이터 사이언티스트


85% 데이터 전처리
15% 모델링


전이학습 = 잘 만든 weight와 model을 가져다 쓰자


스케일링
(내생각) 제일 무난한게 MinMaxScaler, StandardScaler
               X        |    Y
train | fit / transform |    x 
test  |    transform    |    x
val   |    transform    |    x
pred  |    transform    | 값 없음




CNN
컴퓨터는 그림을 숫자로 인식한다 (가로,세로,픽셀)
머신이 그림을 인식할 수 있게, 그림을 잘라서 입력할 수 있다

1x1씩 자르는 게 아니라, 2x2씩 자른다면,
특성값(feature)을 중첩시켜서 머신이 더 확실하게 구분짓도록 유도할 수 있다

이렇게 조각내서 연산하는 방식이 CNN = Convolution Neural Network




특성 중첩을 통해 특징이 더 드러나기 때문에
Convolution layer는 엮을수록 성능이 좋아진다


보통의 프로세스
conv2d를 통과시켜 증폭시키다가
dense를 통과시키면서 압축시킨다



conv2d의 filters 숫자 또한 RNN에서 node개수 처럼,
데이터마다 최적지점이 다르다
사용자가 계산해야 한다


Convolution 에서는, 출력에서 차원이 줄어들지 않는다
LSTM에서 return_sequences 같은 걸 하지 않아도 된다



이미지를 자르는데, 중복시키지 않고 자르는 경우 
= 잘라낸 범위별로 최대값만 찾는 경우
= MaxPooling2D
= (내생각)커진 데이터 이미지를 다시 압축할 때 사용하는 것 같다
https://keras.io/ko/layers/pooling/



Conv2d layer parameter = nowLayer * (width * height * prevLayer +1)




### mnist = 0~9까지의 손글씨 데이터베이스

# 분류 할 때에 중요한 점
각각의 결과값은 동일한 가치를 가져야 한다

# 회귀에서는 RMSE R2 수치를 높이는 게 목표라면
# 분류에서는 분류 결과들이 평등하다는 것을 알려줘야 한다 = One-Hot Encoding
https://wikidocs.net/22647
https://needjarvis.tistory.com/565


### one hot encoding
결과값에 인덱스를 붙여,
분류 할 때에 동일한 가중치를 부여하는 방식

from tensorflow.keras.utils import to_categorical

from sklearn.preprocessing import OneHotEncoder




LSTM의 default activation 
= Default: hyperbolic tangent (tanh)
https://keras.io/api/layers/recurrent_layers/lstm/

Conv2D의 default activation 
= relu
https://keras.io/api/layers/convolution_layers/convolution2d/


다중분류 할 때, 
y 라벨링을 one hot encoding = to_categorical,
마지막 Dense의 activation은 softmax,
컴파일 loss는 categorical_crossentropy


softmax에 의해 나온 결과들을 모두 합치면 1이 된다 ()



201117

mnist에 대한 구현은,

CNN, DNN, LSTM(RNN) 다 가능하다, 가능해야한다



코랩
https://colab.research.google.com/

소스 넣고 돌리면 알아서 동작한다


## 내가 한 중간 질문
model.add(Dense(50))
model.add(activation=~~~) 이런 형태로 따로 돌리기도 하는데,
이건, model.add(Dense(50, activation=~~~))와 같다




### cifar10 데이터셋
그림데이터, (60000,32,32,3)
https://www.cs.toronto.edu/~kriz/cifar.html

airplane : 0
automobile : 1
bird : 2
cat : 3
deer : 4
dog : 5
frog : 6
horse : 7
ship : 8
truck : 9


validation accuracy와 train accuracy가 너무 멀면 과적합



### fashion_mnist 데이터셋
0 T-shirt/top
1 Trouser
2 Pullover
3 Dress
4 Coat
5 Sandal
6 Shirt
7 Sneaker
8 Bag
9 Ankle boot


# cifar100 데이터셋


# cnn 개선하는데 참고중인 사이트들
https://towardsdatascience.com/cifar-10-image-classification-in-tensorflow-5b501f7dc77c

https://buomsoo-kim.github.io/keras/2018/05/05/Easy-deep-learning-with-Keras-11.md/

https://github.com/buomsoo-kim/Easy-deep-learning-with-Keras/blob/master/2.%20CNN/2-Advanced-CNN/2-advanced-cnn.ipynb

https://www.machinecurve.com/index.php/2020/02/09/how-to-build-a-convnet-for-cifar-10-and-cifar-100-classification-with-keras/

https://boysboy3.tistory.com/105

https://stackoverflow.com/questions/58567253/how-would-i-increase-my-accuracy-in-the-cifar-100-dataset-i-have-a-10-accuracy




항상 모든 모델의 최적의 값을 찾아놓자 'ㅁ')/



보통은 node개수를 늘리면 성능이 좋아지긴 하는데,
적당한 한계선은 어떻게 찾아야 할까



Dropout은 값은 가지고 있는데, 작업은 Dropout이 저장된다



### 오전에 한 건 다중분류 / 



# 과제 : 43번 44번도 cnn과 lstm 만들기

CNN을 일단 최대로 올려놓고
DNN과 LSTM을 올려라


### 경험상,
회귀관련 모델링에는 Dropout을 안 쓰는 게 좋겠다



내일은 이진분류 및 그 외의 잡기술



201118
어제 한 모델들은 80~90%는 되어야 한다
그렇게 되도록 하이퍼 파라미터 튜닝을 해놓자


        회귀      |                 분류
---------------------------------------------------
결과가 linear     |      다중분류            |     이중분류
값(실수)가 나온다  | 결과가 여러개            | 결과가 홀짝
                 | activation = 'softmax'   | activation = 'sigmoid'
                 | loss='categorical_crossentropy' | loss='bianry_crossentropy'







데이터 전처리

Scaling

train_test_split





model만 save 할 수 있지만,
fit 하고나서 save 하면, 가중치까지 save 된다
= 동일한 결과를 얻을 수 있다



#1

#2 모델
save_model -> 모델만 저장
load_model -> #3에서 저장한거면 fit이 2번 동작 

#3 컴파일 훈련
save_model -> 모델+가중치까지
load_model -> #3에서 저장한거면 compile+fit까지 모두 되고
              #2에서 저장한거면 compile+fit을 해줘야 한다
save_weight -> 가중치만 저장

#4 


체크포인트에 저장된 것도, 모델+가중치다

accuracy는 조금 달라질 수 있지만,
진짜 기준은 loss 및 val_loss다



### 숙제
keras49의 7개 파일에,
model1 = 모델 로드하고 
model2 = 체크포인트 사용해서
model3 = 가중치 로드

result1 = model1의 결과

예상
model2 성능 > model1 = model3



201119

어제 리뷰 했음

지금까진 load_data나 load_데이터이름 등으로 자료를 가져왔음

현실에서는 보통 csv로 받음 (엑셀 비슷한 것)

첫 시간엔, numpy 형식으로 저장해보기 확장자 '.npy'


npy저장할 때에는 
전처리 전에 할 지 
전처리 후에 할 지 
정해야 한다


가급적이면,
전처리 전에, 순수 데이터를 먼저 npy로 바꾸고
전처리 하는 게 효율적이다
(전처리 기법도 많고, 전처리가 제대로 된지 알 수 없으므로)

### npy 저장/로드 속도 비교자료
https://stackoverflow.com/questions/30329726/fastest-save-and-load-options-for-a-numpy-array

https://stackoverflow.com/questions/9619199/best-way-to-preserve-numpy-arrays-on-disk





지금까지는 정제된 데이터만 사용했다

pandas가 numpy보다 조금 느리지만,
pandas에는 여러 기능들이 더 있다 (head tail 등등등)
numpy는 한가지 데이터형만 사용할 수 있다
섞여있는 데이터라면, pandas를 쓰는게 낫다


pandas를 잘 알면 좋지만, 활용하는 것이 제일 중요하다


오후수업은
Conv1D부터





인공지능 돈 되는 거
시계열(RNN, LSTM) -> 자연어, 퀀트분석
이미지(CNN)



기간상 CNN->GAN, GAN 나가는 게 힘들 수 있다



CNN은 특성뽑기 최적



LSTM의 성능이 보통 1이라 한다면,
Conv1D는 0.998쯤으로 생각하기도 한다 (대체적으로)

근데 LSTM은 겁나 느리다 (연산량에서 x4 하니까)
엄청난 정확도까진 아니라면, 
속도의 장점을 생각한다면, 
Conv1D를 생각할 수도 있다



### 과제
8개 모델들을 LSTM을 Conv1D로 바꿔서 비교해라



주가예측

데이터셋을 받아서 분석하고 모델만들고
소스를 이메일로 제출하면서 끝부분에 예측값 적어서 내기




다중분류 대략 성능
Conv2D > Conv1D > LSTM



<<과제>>
커스텀 스플릿함수 만든 것의 문제

iris 데이터를
150,4를 5개씩 자른다면 146,5,4가 되어야 한다

데이터셋을 자르는 함수 -> 이게 자격증 5번 문제



201120


2시 반까지,
csv를 불러와서
npy로 저장해서 
오늘의 종가를 맞춰라

조건
컬럼 4개 이상 써야함
데이터는 최소 2년 이상
오늘 데이터 잘라내고
하단의 데이터도 잘라내고

앙상블 써서, 파일 하나로

두 데이터의 컬럼 수를 다르게(하나가 4개면 다른 하나는 5개)

메일(kingkeras@naver.com)로 보내기
메일제목 예시,
메일제목: [비트서울] 배현철, 삼성 70,000원





================3시 끝==============

데이터 csv 받는 순간 멍-




### 월요일 시가 맞추기

### 4개의 데이터 셋

### 3,4,5,6 컬럼 수 적용 (각 컬럼 숫자가 달라야 한다)

일요일 23시 59분 59초까지 메일 보내기


금시세와 코스닥은 20일 데이터 사용가능




=================================================================

201123

오늘 할 것, 머신러닝

XG부스터: 
케라스 나오기 전 까지 최고
딥러닝 나오고 조금씩 밀림
그러나 속도가 매우 빠르다


머신러닝 들어가는 이유:
기간이 짧다, 최적화 해서 배우자
딥러닝이 좋다 한들, 
아직까지 머신러닝이 준수한 성능, 빠른 속도

모델을 머신러닝 돌려서 기준값 찾고,
딥러닝으로 최적화

XG는 CPU를 병렬로 사용한다



# 인공지능 역사
2차 세계대전 - 암호 해독
엘런 튜링 - 튜링머신, 튜링게임

인공지능의 암흑기
첫번째 암흑기(1974-1980): "XOR의 문제"
두번째 암흑기(1987-1993)



### LinearSVC
OneHotEncoding 안 해도 된다
모델이 간단하다

다만 XOR 문제에서 최대 0.75
이것이 인공지능의 첫번째 겨울


LinearSVC가 아닌 SVC를 쓰면 문제가 해결됨


# m04_xor2_keras1에서,
Dense 하나만 쓰면 LinearSVC와 같은 결과다


# 뒤에 
Classifier가 붙으면 분류
Regressor가 붙으면 회귀

단, Logistic Regressor는 분류



from sklearn.svm import LinearSVC, SVC
from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
위에 모델들은 validation이 없다

XGbooster에는 있다 (나중에 한다)



미니 개인프로젝트 1번
1일~1주일
주제에 대해 생각해보자
발표시간 5분
원천기술(소스) 


팀프로젝트 3인 1조


최종 진도는,
강화학습x
자연어처리 못함 (시간이 안 됨)
GAN도 힘들다





# wine2 target 분포
# quality
# 3      20
# 4     163
# 5    1457
# 6    2198
# 7     880
# 8     175
# 9       5
# Name: quality, dtype: int64

5,6,7에 치중되어 있다
데이터카 큰 쪽으로 훈련하고, 성능이 좋은 것 처럼 보일 수 있다
그래서 때로는, 카테고리를 통합하는 것도 하나의 방법일 수 있다


내일은,
validation 한다
모델 전 튜닝

아침부터
PCA 한다



=============

201124

검증의 문제
데이터가 100개가 있다면, validation 0.2면 20개로 검증할텐데,
그 개수가 맞나?
데이터셋의 검증에 대표성이 있나? 
-> 기준이 없다

20개씩 5번 훈련하면, 즉, 전체 데이터로 검증하면 어떨까


모든 검증의 문제 = 한 번 검증한 것을 믿을 수 있겠냐

Cross Validation = CV = K-Fold


0.2 test 비율에, cv=5 하면 모든 데이터를 다 사용하여 검증했으니,
효율적으로 데이터를 사용한 것으로 볼 수 있다



하이퍼파리미터튜닝 하면서,
계속 주관적인 튜닝을 해왔다
-> 좀 더 객관적으로 튜닝해보자


# 그리드서치
하이퍼파리미터를 싹 모아서, 그리드(격자) 모양으로 찾는 기능

그리드서치 결과 또한 매번 변하긴 한다




오후수업
데이터 낭비가 있는 것 같아서 = 모든 데이터 검증 = KFold = CV
파라미터 튜닝도 주관->객관 하기 위해 XXXSearchCV




여태 오전에 하면서 안 한 것 한가지 = 스케일링
쓸만한거 6개 (배운거 4개)



파이프라인을 사용하는 이유는
CV의 경우, 모든 범위를 fit 하기 때문에,
답안지 놓고 문제푸는 것과 비슷하다 = 과적합
train만 fit 하고, 나머지 transform 하기 위해서

= CV에서 과적합 피하기 위해



cv=5 라는 건
5회 반복 = 데이터를 4/5 train, 1/5는 validation


# 나무를 보지 말고 숲을 봐라
= decisionTree를 보지 말고 RandomForest를 봐라

decisionTree들이 모인거 = RandomForest

RandomForest + Boosting = XGbooster

트리구조 머신러닝이 성능이 제일 좋다


print(model.feature_importances_)
총 합은 1

[0.         0.         0.         0.00677572 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.05612587 0.78000877 0.01008994
 0.02293065 0.         0.         0.11729332 0.00677572 0.        ]

30개의 컬럼 중에,
각 수치는, 영향력이다

영향력 있는 애들만 모아서 돌려도 된다


내일 할 것
feature를 바꿀 것이다





========================================================

201125

model.feature_importances_ 를 이용해서 feature를 뽑아낸다
뽑아서 사용할 수 있다
데이터 조작이라기 보다는, 데이터 전처리 개념

부스팅 계열은 성능이 거의 비슷하다




# 지도학습 - 라벨링이 있다, 답을 알려주고 정답을 맞추는 것
분류와 회귀

# 비지도학습 - 라벨링이 없다, 비슷한 데이터를 군집화 하는 것

# PCA = 주성분분석
- 비지도학습
- 차원축소


당뇨병예제에서,
X 컬럼이 30개인데, Y는 1개
이건 마치, 30개가 1개로 축소된 것 처럼 생각할 수 있지 않을까


원본X - 차원축소X - Y 라는 가정하에,

원본X 입장에선 차원축소X는 Y라고 할 수 있고,
Y 입장에선 차원축소X는 X라고 할 수 있다


PCA로 중간 과정을 거쳐서 중요한 컬럼을 찾아낼 수 있기 때문에 많이 사용된다


# 앞으로의 대충 과정
PCA -> XGbooster -> keras 묶기 -> 이미지셋 -> 미니플젝 -> 고급스킬들


sum(pca_EVR): 0.9479436357350411
선택한 n_components=7로 인해,
원본 데이터에서 94% 정도 대표성을 띄는 데이터를 만들 수 있다 = 차원축소



# PCA는 전처리 개념
# feature를 한 번 정리해서 가장 대표성을 띄는 데이터만 사용한다






PCA를 적용하려 하니,
데이터 전처리 순서가 뒤바뀐다

데이터 전처리 하는 항목만 정리하자
(순서는 언제든 바뀔 수 있다, 고정된 게 아니다)
- OneHotEncoding
- Reshape
- XXXScaler
- (StandardScaler+)PCA
- train_test_split



PCA를 적용할 때,
PCA 전에 StandardScaler를 하면,
PCA에 성능을 올릴 수 있다

지금 하고 있는 건, 
feature engineering
feature impotance


F score 확인하기
https://deepai.org/machine-learning-glossary-and-terms/f-score



### 개인프로젝트
26일 오후에 주제 발표
리젝당했다면 금요일 다시 발표

금토일월
발표는 화요일 오전


=========================================================

201126

데이터전처리
feature engineering
많이 해보는 수 밖에



SelectFromModel

feature_importances_의 갯수만큼 실행하여,
Threshold와 feature갯수에 따른 score를 비교할 수 있다



[Keras] 대용량 데이터 세트에서 딥 러닝 모델을 학습하려는 경우 Keras에 대해 알아야 할 사항
https://medium.com/difference-engine-ai/keras-a-thing-you-should-know-about-keras-if-you-plan-to-train-a-deep-learning-model-on-a-large-fdd63ce66bd2








